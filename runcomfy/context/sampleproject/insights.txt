# RunComfy API Integration Insights
## Complete Implementation Documentation for forMat Project

### Core RunComfy Integration Files

#### **Primary Backend Files:**
1. **`backend/app/runcomfy_client.py`** - Low-level RunComfy API client
2. **`backend/app/runcomfy_orchestrator.py`** - High-level workflow orchestration
3. **`backend/app/comfyui_workflow_client.py`** - ComfyUI workflow execution client
4. **`backend/app/services.py`** - Service layer integration (cloud mode)
5. **`backend/app/runcomfy_routes.py`** - FastAPI routes for RunComfy endpoints
6. **`backend/app/main.py`** - Environment configuration and mode selection

#### **Frontend Files:**
7. **`js/runcomfy-api.js`** - Frontend RunComfy API wrapper (unused in final implementation)
8. **`js/api.js`** - Main API client with RunComfy support
9. **`main.py`** - Application launcher with RunComfy configuration

#### **Configuration & Documentation:**
10. **`RUNCOMFY_CONFIG.md`** - Configuration documentation
11. **`runcomfyPLAN.txt`** - Implementation planning document
12. **`workflowexplanation.txt`** - Workflow integration strategy
13. **`backend/test_runcomfy.py`** - Testing utilities
14. **`debug_runcomfy_quick.py`** & **`debug_runcomfy_workflow.py`** - Debug tools

---

## 1. How We Did It: Complete Implementation Strategy

### **Architecture Overview**
```
Frontend (User Interface)
    ↓ (HTTP POST /api/jobs)
Backend Service Layer (services.py)
    ↓ (Async Background Task)
RunComfy Orchestrator (runcomfy_orchestrator.py)
    ↓ (Machine Management)
RunComfy API Client (runcomfy_client.py)
    ↓ (ComfyUI Execution)
ComfyUI Workflow Client (comfyui_workflow_client.py)
    ↓ (Image Generation)
Generated Images → Frontend Display
```

### **Key Implementation Decisions**

#### **1. Multi-Layer Architecture**
- **Service Layer**: Handles mode switching (local vs cloud)
- **Orchestrator Layer**: Manages complete job lifecycle
- **Client Layer**: Direct API communication
- **Workflow Layer**: ComfyUI-specific operations

#### **2. Async Background Processing**
- Main HTTP request returns immediately with "queued" status
- Background task handles the 100-500 second workflow execution
- File data is read immediately to prevent file handle closure issues

#### **3. File Handling Solution**
```python
# CRITICAL FIX: Read image data before background task
image_content = await image.read()
asyncio.create_task(self._execute_cloud_job_async(
    job_id, image_content, image.filename, image.content_type, prompt
))
```

#### **4. Machine Lifecycle Management**
```python
# Complete workflow execution process
1. get_or_create_machine() → Launch/reuse RunComfy machine
2. prepare_workflow() → Inject user data into workflow JSON
3. execute_workflow() → Submit to ComfyUI instance
4. wait_for_completion_websocket() → Monitor execution
5. save_generated_images() → Download and save results
6. cleanup_machine() → Optional machine cleanup
```

---

## 2. Clear Steps for Integrating RunComfy API in Other Software

### **Step 1: Environment Setup**
```bash
# Required environment variables
RUNCOMFY_API_BASE_URL=https://api.runcomfy.net
RUNCOMFY_USER_ID=your-user-id-from-dashboard
RUNCOMFY_API_TOKEN=your-api-token
COMFYUI_MODE=cloud
```

### **Step 2: Install Dependencies**
```python
# Required Python packages
httpx          # Async HTTP client
websockets     # WebSocket monitoring
loguru         # Logging
fastapi        # Web framework (if building API)
python-multipart  # File upload handling
```

### **Step 3: Core Client Implementation**
```python
class RunComfyAPIClient:
    def __init__(self):
        self.base_url = os.getenv("RUNCOMFY_API_BASE_URL")
        self.user_id = os.getenv("RUNCOMFY_USER_ID") 
        self.api_token = os.getenv("RUNCOMFY_API_TOKEN")
    
    @property
    def headers(self):
        return {
            "Authorization": f"Bearer {self.api_token}",
            "Accept": "application/json",
            "Content-Type": "application/json"
        }
    
    async def launch_machine(self, version_id, server_type="medium"):
        # Launch RunComfy machine
    
    async def wait_for_machine_ready(self, server_id):
        # Poll until machine is ready
    
    async def stop_machine(self, server_id):
        # Clean up machine
```

### **Step 4: Workflow Client Implementation**
```python
class ComfyUIWorkflowClient:
    async def execute_workflow(self, comfyui_url, workflow, image, prompt, job_id):
        # 1. Prepare workflow with user data
        prepared_workflow = self.prepare_workflow(workflow, image, prompt)
        
        # 2. Submit to ComfyUI
        prompt_id, client_id = await self.submit_workflow(comfyui_url, prepared_workflow)
        
        # 3. Monitor execution via WebSocket
        execution = await self.wait_for_completion_websocket(comfyui_url, prompt_id, client_id)
        
        # 4. Download and save results
        saved_images = await self.save_generated_images(comfyui_url, execution.outputs, job_id)
        
        return execution, saved_images
```

### **Step 5: Service Layer Integration**
```python
class YourService:
    def __init__(self):
        self.mode = os.getenv("COMFYUI_MODE", "cloud")
        if self.mode == "cloud":
            self.runcomfy_orchestrator = RunComfyOrchestrator()
    
    async def queue_job(self, job_id, image, prompt):
        if self.mode == "cloud":
            # Read image data immediately (CRITICAL!)
            image_content = await image.read()
            
            # Start background task with raw data
            asyncio.create_task(self._execute_cloud_job_async(
                job_id, image_content, image.filename, image.content_type, prompt
            ))
            
            return {"status": "queued", "job_id": job_id}
```

### **Step 6: Background Execution**
```python
async def _execute_cloud_job_async(self, job_id, image_data, filename, content_type, prompt):
    try:
        # Create mock UploadFile from raw data
        mock_image = MockUploadFile(image_data, filename, content_type)
        
        # Execute via orchestrator
        job = await self.runcomfy_orchestrator.execute_job(job_id, mock_image, prompt)
        
        # Job completed successfully
        
    except Exception as e:
        # Handle errors
        logger.error(f"Background job {job_id} failed: {e}")
```

---

## 3. Common Gotchas and Errors

### **🚨 Critical File Handling Issue**
**Problem**: `ValueError: I/O operation on closed file`
**Cause**: Trying to access UploadFile objects in background tasks after HTTP request completes
**Solution**: Read file data immediately before starting background task
```python
# ❌ WRONG - Will crash
asyncio.create_task(process_job(job_id, image, prompt))

# ✅ CORRECT - Read data first
image_content = await image.read()
asyncio.create_task(process_job(job_id, image_content, image.filename, image.content_type, prompt))
```

### **🚨 WebSocket Connection Issues**
**Problem**: WebSocket monitoring fails or times out
**Cause**: Incorrect URL format or firewall issues
**Solution**: Use proper WebSocket URL conversion and fallback to polling
```python
# Convert HTTP to WebSocket URL
ws_url = comfyui_url.replace("https://", "wss://").replace("http://", "ws://")
ws_url = f"{ws_url}/ws?clientId={client_id}"

# Always have polling fallback
try:
    return await self.wait_for_completion_websocket(comfyui_url, prompt_id, client_id)
except Exception:
    return await self.wait_for_completion(comfyui_url, prompt_id)  # Polling fallback
```

### **🚨 Machine Launch Timeouts**
**Problem**: Machines take too long to become ready
**Cause**: RunComfy cloud infrastructure delays
**Solution**: Implement proper timeout handling and retry logic
```python
# Use appropriate timeouts for cloud operations
machine_timeout = 600  # 10 minutes for machine readiness
execution_timeout = 2000  # 33 minutes for workflow execution
```

### **🚨 Image Data Corruption**
**Problem**: Generated images are incomplete or corrupted
**Cause**: Trying to serve images while ComfyUI is still writing them
**Solution**: Implement file stability checks
```python
def check_file_stability(file_path):
    stat1 = file_path.stat()
    time.sleep(0.1)
    stat2 = file_path.stat()
    
    return (stat1.st_size == stat2.st_size and 
            stat1.st_mtime == stat2.st_mtime and
            stat1.st_size > 1000)
```

### **🚨 API Rate Limiting**
**Problem**: RunComfy API returns 429 Too Many Requests
**Cause**: Exceeding rate limits
**Solution**: Implement exponential backoff
```python
async def _make_request_with_retry(self, method, endpoint, json_data=None, max_retries=3):
    for attempt in range(max_retries):
        try:
            response = await client.request(method, url, json=json_data, headers=self.headers)
            if response.status_code == 429:
                wait_time = 2 ** attempt
                await asyncio.sleep(wait_time)
                continue
            response.raise_for_status()
            return response.json()
        except Exception as e:
            if attempt == max_retries - 1:
                raise e
```

### **🚨 Cost Management Issues**
**Problem**: Forgetting to stop machines leading to unexpected costs
**Cause**: Not implementing proper cleanup
**Solution**: Always implement machine cleanup with error handling
```python
# Always cleanup in finally block
try:
    job = await self.execute_workflow(...)
finally:
    if machine_info and auto_shutdown:
        await self.cleanup_machine(machine_info.server_id)
```

---

## 4. Prompt to Replicate This in New Software Using Other Coding Agent

### **Comprehensive Integration Prompt**

```
I need you to implement RunComfy API integration in my [LANGUAGE/FRAMEWORK] application. 

GOAL: Create a system that can execute ComfyUI workflows on RunComfy cloud infrastructure.

ARCHITECTURE REQUIREMENTS:
1. Multi-layer architecture: API Client → Orchestrator → Service Layer
2. Async background processing for long-running workflows (100-500 seconds)
3. Proper file handling to prevent file closure issues
4. WebSocket monitoring with polling fallback
5. Machine lifecycle management (launch, monitor, cleanup)
6. Error handling and retry logic

CORE COMPONENTS TO IMPLEMENT:

1. **RunComfyAPIClient** - Low-level API communication
   - Machine launch/stop operations
   - Workflow management
   - Proper authentication with Bearer tokens
   - Rate limiting and retry logic

2. **ComfyUIWorkflowClient** - ComfyUI-specific operations
   - Workflow preparation and data injection
   - WebSocket monitoring for real-time progress
   - Image download and processing
   - File stability checks

3. **RunComfyOrchestrator** - High-level workflow management
   - Complete job lifecycle management
   - Machine reuse optimization
   - Cost estimation and cleanup
   - Error recovery

4. **Service Integration** - Application-specific integration
   - File handling (CRITICAL: read data before background tasks)
   - Job status tracking
   - Frontend API endpoints

CRITICAL IMPLEMENTATION DETAILS:

File Handling Pattern:
```
// Read file data immediately before background processing
const imageData = await readFileData(uploadedFile);
startBackgroundTask(jobId, imageData, fileName, contentType, prompt);
```

WebSocket Monitoring:
```
wsUrl = comfyuiUrl.replace('https://', 'wss://') + '/ws?clientId=' + clientId;
// Always implement polling fallback for reliability
```

Error Patterns to Avoid:
- Never pass file handles to background tasks
- Always implement machine cleanup
- Use proper timeouts (10min machine ready, 35min execution)
- Implement file stability checks before serving images
- Handle rate limiting with exponential backoff

Environment Configuration:
```
RUNCOMFY_API_BASE_URL=https://api.runcomfy.net
RUNCOMFY_USER_ID=your-user-id
RUNCOMFY_API_TOKEN=your-token
COMFYUI_MODE=cloud
```

Expected Flow:
1. User submits image + prompt
2. Read file data immediately
3. Start background task with raw data
4. Launch/reuse RunComfy machine
5. Execute workflow on ComfyUI instance
6. Monitor via WebSocket (fallback to polling)
7. Download generated images with stability checks
8. Return results to user
9. Optional machine cleanup

Please implement this step-by-step, following the multi-layer architecture pattern, and pay special attention to the file handling and error recovery patterns that prevent the common crashes and issues.
```

---

## Summary

This RunComfy integration represents a production-ready implementation that handles:
- ✅ **Stable async processing** without file handle issues
- ✅ **Robust error handling** with fallback mechanisms  
- ✅ **Cost optimization** through machine lifecycle management
- ✅ **Real-time monitoring** via WebSocket with polling backup
- ✅ **File integrity checks** to prevent corruption issues
- ✅ **Scalable architecture** supporting both cloud and local modes

The key insight is that cloud API integration requires careful handling of async operations, file lifecycles, and network reliability - all of which are addressed in this implementation.
